{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of how to carry out Domain Adaptation between a source (MNIST) Dataset and target (Fashion-MNIST) Dataset.\n",
    "#just switch dataset combinations to carry out DA between different pairs of datasets ( also change the number of classes accordingly)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "#Training a LeNet5 on the source MNIST Dataset \n",
    "mnisttt = fetch_openml('mnist_784') \n",
    "\n",
    "mnist = pd.concat([pd.DataFrame(mnisttt.data), pd.DataFrame({ 'target' : mnisttt.target})], axis = 1)\n",
    "\n",
    "mnist =shuffle(mnist, random_state = 2)\n",
    "\n",
    "source_dataset = pd.DataFrame(mnist.iloc[:,0:784]).to_numpy()\n",
    "\n",
    "source_labels = pd.DataFrame(mnist.target).to_numpy()\n",
    "\n",
    "# Reshape the data to a (70000, 28, 28) tensor\n",
    "source_data = source_dataset.reshape((source_dataset.shape[0], 28, 28 ))\n",
    "# Reshape the data to a (70000, 28, 28, 1) tensord\n",
    "source_data = source_data[:, :, :, np.newaxis]\n",
    "\n",
    "# Scale values from range of [0-255] to [0-1]\n",
    "scaled_source_data = source_data / 255.0\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(\n",
    "    scaled_source_data,\n",
    "    source_labels.astype(\"int\"), \n",
    "    test_size = 1/7)\n",
    "\n",
    "# Tranform training labels to one-hot encoding\n",
    "train_labels = np_utils.to_categorical(train_labels, 10)\n",
    "\n",
    "# Tranform test labels to one-hot encoding\n",
    "test_labels = np_utils.to_categorical(test_labels, 10)\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolution layer\n",
    "model.add(Convolution2D(\n",
    "    filters = 20,\n",
    "    kernel_size = (5, 5),\n",
    "    padding = \"same\",\n",
    "    input_shape = (28, 28, 1)))\n",
    "\n",
    "# Add a ReLU activation function\n",
    "model.add(Activation(\n",
    "    activation = \"relu\"))\n",
    "\n",
    "# Add a pooling layer\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size = (2, 2),\n",
    "    strides =  (2, 2)))\n",
    "\n",
    "# Add the second convolution layer\n",
    "model.add(Convolution2D(\n",
    "    filters = 50,\n",
    "    kernel_size = (5, 5),\n",
    "    padding = \"same\"))\n",
    "\n",
    "# Add a ReLU activation function\n",
    "model.add(Activation(\n",
    "    activation = \"relu\"))\n",
    "\n",
    "# Add a second pooling layer\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size = (2, 2),\n",
    "    strides = (2, 2)))\n",
    "\n",
    "# Flatten the network\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully-connected hidden layer\n",
    "model.add(Dense(500))\n",
    "\n",
    "# Add a ReLU activation function\n",
    "model.add(Activation(\n",
    "    activation = \"relu\"))\n",
    "\n",
    "# Add a fully-connected output layer\n",
    "model.add(Dense(10))\n",
    "\n",
    "# Add a softmax activation function\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "adam = Adam(lr=1e-3, decay=1e-6)\n",
    "\n",
    "# Compile the network\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy', \n",
    "    optimizer = adam,\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "model.fit(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    batch_size = 128, \n",
    "    nb_epoch = 20,\n",
    "\t  verbose = 1)\n",
    "\n",
    "# Evaluate the model\n",
    "(loss, accuracy) = model.evaluate(\n",
    "    test_data, \n",
    "    test_labels,\n",
    "    batch_size = 128, \n",
    "    verbose = 1)\n",
    "\n",
    "# Print the model's accuracy\n",
    "print(accuracy)\n",
    "\n",
    "#save trained network\n",
    "model.save('train_mnist.h5')\n",
    "\n",
    "\n",
    "#load saved network and weights\n",
    "model =models.load_model('train_mnist.h5')\n",
    "model.load_weights('train_mnist.h5')\n",
    "new_model = Sequential() \n",
    "\n",
    "for layer in model.layers:\n",
    "    new_model.add(layer) # copying previously saved network\n",
    "\n",
    "for layer in new_model.layers[:-5]:\n",
    "    layer.trainable = False  #for fine-tuning on target dataset need to freeze top three layers\n",
    "\n",
    "#Fine-tuning pre-trained network on target Fashion-MNIST Dataset\n",
    "fmnistt = fetch_openml('Fashion-MNIST') \n",
    "    \n",
    "fmnist = pd.concat([pd.DataFrame(fmnistt.data), pd.DataFrame({ 'target' : fmnistt.target})], axis = 1)\n",
    "\n",
    "fmnist =shuffle(fmnist, random_state = 2)\n",
    "\n",
    "target_dataset = pd.DataFrame(fmnist.iloc[:,0:784]).to_numpy()\n",
    "\n",
    "target_labels = pd.DataFrame(mnist.target).to_numpy()\n",
    "\n",
    "# Reshape the data to a (70000, 28, 28) tensor\n",
    "target_data = target_dataset.reshape((target_dataset.shape[0], 28 , 28))\n",
    "\n",
    "# Reshape the data to a (70000, 28, 28, 1) tensord\n",
    "target_data = target_data[:, :, :, np.newaxis]\n",
    "\n",
    "# Scale values from range of [0-255] to [0-1]\n",
    "scaled_target_data = target_data / 255.0\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(\n",
    "    scaled_target_data,\n",
    "    target_labels.astype(\"int\"), \n",
    "    test_size = 1/7)\n",
    "\n",
    "# Tranform training labels to one-hot encoding\n",
    "train_labels = np_utils.to_categorical(train_labels, 10)\n",
    "\n",
    "# Tranform test labels to one-hot encoding\n",
    "test_labels = np_utils.to_categorical(test_labels, 10)\n",
    "\n",
    "\n",
    "adam = Adam(lr=1e-3, decay=1e-6)\n",
    "\n",
    "# Compile the network\n",
    "new_model.compile(\n",
    "    loss = 'categorical_crossentropy', \n",
    "    optimizer = adam,\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "new_model.fit(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    batch_size = 128, \n",
    "    epochs = 10,\n",
    "\t  verbose = 1)\n",
    "\n",
    "# Evaluate the model\n",
    "(loss, accuracy) = new_model.evaluate(\n",
    "    test_data, \n",
    "    test_labels,\n",
    "    batch_size = 128, \n",
    "    verbose = 1)\n",
    "\n",
    "# Print the model's accuracy\n",
    "print('accuracy of a MNIST-pre-trained neural network on FMNIST:', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "new_model.save('train_mnist-fmnist.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
